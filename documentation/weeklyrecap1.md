# Weekly report

## Getting to know what I'm about to do
The first week of this project was dedicated to learning as much as possible about what is to come and how everything should be done. Different approaches were also evaluated to find the optimal way to learn and also get something done. So zero lines of code this week.

I learned a lot about the basic structure of a simple neural network. On top of that many methods like forward pass, backpropagation, loss function, gradient descent, training process, and implementation of these concepts were things I dived into this week. I tried to get the basic knowledge of the whole concept and with that understand as much as I can about these things that I'm about to apply in my work. And I did learn.

Of course building and training such models are still a mystery to me. Especially the implementation of the math is the thing that I need to learn more about so I can choose the best ways of doing things like activation functions and actually choose the right one to fit this type of approach. The biggest of all things that makes me nervous is testing such a model in the right way. That is something I will be focusing on next week + all other stuff that I still don't know. 

> [Deep Learning](https://www.deeplearningbook.org/) MIT Press book, reading this during this project
